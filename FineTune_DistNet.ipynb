{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTune_DistNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KPAllard/BDC---PTA/blob/master/FineTune_DistNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZCXJxXA_Ivc"
      },
      "source": [
        "# Initialize GPU\n",
        "\n",
        "The next cell is check that GPU is not a K80 for a faster training. If K80, choose Execution>Manage Session, stop the current session, refresh page and re-run the cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOea4IleCCjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4786b9dc-fec9-4fab-976e-d21576c2c03b"
      },
      "source": [
        "!nvidia-smi "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Dec  5 15:19:40 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDiKy27Y-ifY"
      },
      "source": [
        "# Downaload Dataset & model weights\n",
        "Set the 5 first variables of the next cell.\n",
        "The .h5 dataset should follow [this file architecture](https://github.com/jeanollion/dataset_iterator). See [this page](https://github.com/jeanollion/bacmman/wiki/FineTune-DistNet) to generate is with BACMMAN software.\n",
        "\n",
        "Follow instructions in the output of the cell to mount the google drive that contains the .h5 dataset file. \n",
        "\n",
        "Model weights will be downloaded. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcM2QUOSdiM8"
      },
      "source": [
        "drive_folder = \"Segmentation\" # folder containing dataset in google drive\n",
        "dataset_name = \"bacteriaSegTrackEDM.h5\" # name of the hdf5 dataset file\n",
        "training_selection_name = \"ds_noError/\" # name of the training selection\n",
        "validation_selection_name = \"ds_noError_test/\" # name of the validation selection\n",
        "saved_model_file = \"distNet_fine-tuned.zip\" # name of the exported zipped model file\n",
        "\n",
        "raw_feature_name = \"/raw\" # raw input channel\n",
        "label_feature_name = \"/regionLabels\" # bacteria labels\n",
        "pre_label_feature_name = \"/prevRegionLabels\" # label of previous bacteria\n",
        "\n",
        "# mount google drive: follow the link, choose the account that contains the dataset and paste token in the displayed field\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "def mount_drive():\n",
        "  drive.mount('/content/driveDL', force_remount=True)\n",
        "  os.chdir(\"/content/driveDL/My Drive/\"+drive_folder)\n",
        "mount_drive()\n",
        "\n",
        "# install dependencies\n",
        "!pip install --upgrade h5py==2.9\n",
        "!pip install edt\n",
        "!pip install git+https://github.com/jeanollion/distnet.git\n",
        "!pip install git+https://github.com/jeanollion/dataset_iterator.git\n",
        "# copy dataset locally\n",
        "!cp \"$dataset_name\" \"/home/bacteriaSegTrack.h5\"\n",
        "# download weights\n",
        "!gdown \"https://drive.google.com/uc?export=download&id=1-3VmrlUINU-OpC1JnaNA3iM-dztltDCJ\" -O \"/home/distNet_weights.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DioFrGu4_Sbw"
      },
      "source": [
        "# Initialize dataset iterator & data augmentation & model\n",
        "\n",
        "- Data augmentation parameters (parameters of `ImageDataGeneratorMM` ) should be modified according to the dataset. Use the command in the visualize section to check that data augmentation do not produce unrealistic images, in particular the aspect ratio limits (so that transformed cells are not too thin / not to fat) \n",
        "\n",
        "- The amount of data should be carefully chosen, according to the task. It should contain all the diversity that has to be processed, as well as a few empty channels. \n",
        "\n",
        "- We achieved similar performance as on the orginal training dataset using ~2500 microchannels for training and ~750 for validation. \n",
        "\n",
        "- Training and validation sets should be chosen among distinct microchannels to avoid bias. \n",
        "\n",
        "- Starting learning rate should also be carefully chosen. We achieved good results using 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjw8jp8zeAec"
      },
      "source": [
        "import h5py\n",
        "from dataset_iterator import DyIterator\n",
        "from distnet.data_generator import ImageDataGeneratorMM\n",
        "import distnet.keras_models as km\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from distnet.utils.losses import weighted_loss_by_category\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy, mean_absolute_error, mean_squared_error\n",
        "\n",
        "\n",
        "label_datagen = ImageDataGeneratorMM(\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=5, height_shift_range=40,\n",
        "    width_zoom_range=[0.5, 1.5],\n",
        "    height_zoom_range=[0.8, 1.2],\n",
        "    min_zoom_aspectratio=0.5,\n",
        "    max_zoom_aspectratio=2.5,\n",
        "    rotation_range=3,\n",
        "    shear_range=20,\n",
        "    bacteria_swim_distance=40,\n",
        "    perform_illumination_augmentation=False,\n",
        "    interpolation_order=0\n",
        ")\n",
        "image_datagen = ImageDataGeneratorMM(interpolation_order=1, perform_illumination_augmentation=True)\n",
        "params = dict(dataset='/home/bacteriaSegTrack.h5', \n",
        "              channel_keywords=[raw_feature_name, label_feature_name, pre_label_feature_name], # channel keyword must correspond to the name of the extracted features\n",
        "              image_data_generators=[image_datagen, label_datagen, label_datagen],\n",
        "              output_channels=[1, 2],\n",
        "              mask_channels=[1, 2],\n",
        "              channels_prev=[True, True, False],\n",
        "              channels_next=[False]*3,\n",
        "              compute_edm=\"all\",\n",
        "              erase_cut_cell_length=20,\n",
        "              closed_end=True,\n",
        "              return_categories=True,\n",
        "              batch_size=64,\n",
        "              perform_data_augmentation=True,\n",
        "              shuffle=True)\n",
        "\n",
        "train_it = DyIterator(group_keyword=training_selection_name, **params)\n",
        "test_it = DyIterator(group_keyword=validation_selection_name, **params) # alternatively one can use train_test_split method to split the dataset. \n",
        "\n",
        "dy_loss = mean_absolute_error\n",
        "edm_loss = mean_squared_error\n",
        "class_loss=weighted_loss_by_category(sparse_categorical_crossentropy, [1, 1, 5, 5])\n",
        "\n",
        "model = km.get_distnet_model()\n",
        "\n",
        "model.compile(optimizer=Adam(1e-5), loss=[dy_loss, class_loss, edm_loss], loss_weights=[0.5, 1, 1]) # training from scratch can start at a higher learning rate such as 2e-4\n",
        "model.load_weights(\"/home/distNet_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWZNhZPi_Yak"
      },
      "source": [
        "# Perform fine-tuning\n",
        "Run this cell to perform fine-tuning. Tab should stay opened during the whole training. \n",
        "\n",
        "Intermediate weights are stored in google drive in the file *distNet_fineTuned_cp.h5*. If the runtime was disconnected, they can be loaded with the command: `model.load_weights(\"distNet_fineTuned_cp.h5\")`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7_6XxcbgxIs"
      },
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import numpy as np\n",
        "from distnet.utils import PatchedModelCheckpoint\n",
        "\n",
        "train_it._close_datasetIO()\n",
        "test_it._close_datasetIO()\n",
        "checkpoint = PatchedModelCheckpoint(\"/home/model_cpV_{epoch:02d}.h5\", filepath_dest=\"distNet_fineTuned_cp.h5\", timeout_function=mount_drive, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
        "lr_schedule = ReduceLROnPlateau(min_lr=1e-6, factor=0.5, patience=5, verbose=1, min_delta=0.001)\n",
        "\n",
        "model.fit_generator(train_it, epochs=30, validation_data=test_it, callbacks=[lr_schedule, checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IPT9_zV_mrE"
      },
      "source": [
        "# Save model for prediction\n",
        "\n",
        "Open the following notebook in colab in order to convert the .h5 weight file into a model that can be used by tensorflow for prediction: \n",
        " [![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1LVrBoazWq9xcrt2Ea3ArILvMApfTyvwp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CCOhhjt_cGg"
      },
      "source": [
        "# Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-bORbDji6g4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "batch_size = test_it.batch_size\n",
        "test_it.batch_size = 10\n",
        "x_test, [dy_test, category_test, edm_test] = test_it.next()\n",
        "[dy_pred, category_pred, edm_pred] = model.predict(x_test)\n",
        "plot_category = False\n",
        "plt.figure(figsize=(22, 8))\n",
        "n_im_show = 2 + 2 + 2 + (5 if plot_category else 0 ) + 1\n",
        "n_subdiv = n_im_show * test_it.batch_size // 2\n",
        "for i in range(0, test_it.batch_size):\n",
        "    j=1\n",
        "    plt.subplot(2, n_subdiv, n_im_show*i + j)\n",
        "    plt.imshow(x_test[i,:,:,0], cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Prev\")\n",
        "    j+=1\n",
        "    plt.subplot(2, n_subdiv, n_im_show*i + j)\n",
        "    plt.imshow(x_test[i,:,:,1], cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Cur\")\n",
        "    j+=1\n",
        "    \n",
        "    # dy\n",
        "    vdis = max(abs(dy_test[i,:,:, 0].min()),abs(dy_test[i,:,:, 0].max()))\n",
        "    plt.subplot(2, n_subdiv, n_im_show*i + j)\n",
        "    plt.imshow(dy_test[i,:,:, 0], cmap=\"bwr\", vmin=-vdis, vmax=vdis)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"GT\")\n",
        "    j+=1\n",
        "    plt.subplot(2, n_subdiv, n_im_show*i + j)\n",
        "    plt.imshow(dy_pred[i,:,:, 0], cmap=\"bwr\", vmin=-vdis, vmax=vdis)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"dY\")\n",
        "    j+=1\n",
        "    \n",
        "    # edm current\n",
        "    vedm = max(0, edm_pred[i,:,:, 1].max())\n",
        "    plt.subplot(2, n_subdiv, n_im_show*i + j)\n",
        "    plt.imshow(edm_pred[i,:,:,0], cmap=\"gray\", vmin=0, vmax=vedm)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Prev\")\n",
        "    j+=1\n",
        "    plt.subplot(2, n_subdiv, n_im_show*i + j)\n",
        "    plt.imshow(edm_pred[i,:,:,1], cmap=\"gray\", vmin=0, vmax=vedm)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Cur\")\n",
        "    j+=1\n",
        "\n",
        "    if plot_category:\n",
        "      plt.subplot(2, n_subdiv, n_im_show*i + j)\n",
        "      plt.imshow(category_test[i,:,:,0], cmap=\"rainbow\", vmin=0, vmax=3)\n",
        "      plt.axis(\"off\")\n",
        "      j+=1\n",
        "      for c in range(4):\n",
        "        plt.subplot(2, n_subdiv, n_im_show*i + j)\n",
        "        plt.imshow(category_pred[i,:,:,c], cmap=\"gray\", vmin=0, vmax=1)\n",
        "        plt.axis(\"off\")\n",
        "        j+=1\n",
        "\n",
        "plt.show()\n",
        "test_it.batch_size = batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2_biK4FRfnY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}